{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2f838-68a8-4dc7-966e-40a087342574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b590212-9db2-4673-bc22-740771c25266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32347f6-3d98-40e8-97db-185a5739cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bba569-825e-44ba-9c84-97e01f013d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e31ed-c843-4ac2-95cc-070216e18f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.consumer import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d156d7-c6ae-40fb-88a3-0a1284d3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.producer import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d56fc-d215-4574-9a9c-6b8d3b0f4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from transformers import pipeline\n",
    "import ssl\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1cfc6-f1a2-48e6-b13f-11923691b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def analyze_sentiment(text):\n",
    "#    classifier = pipeline(\"sentiment-analysis\")\n",
    "#    result = classifier(text)[0]\n",
    "#    return result[\"label\"]\n",
    "\n",
    "bootstrap_servers = ['globex-ret-cgbv--fs---qsv-ajjig.bf2.kafka.rhcloud.com:443']\n",
    "topic = 'consume-topic'\n",
    "produce_topic = 'produce-topic'\n",
    "username = '5c8037b6-8d56-4160-8ea5-e6921d1da5fb'\n",
    "password = 'affyRJrfk2eYJBcQtQDstnVUGcLXA78U'\n",
    "sasl_mechanism = 'PLAIN'\n",
    "security_protocol = 'SASL_SSL'\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    "    auto_offset_reset='latest',\n",
    "    enable_auto_commit=True,\n",
    ")\n",
    "\n",
    "# Set up a Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    ")\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Continuously listen for incoming messages and analyze their sentiment\n",
    "#for message in consumer:\n",
    "#    text = message.value.decode('utf-8')\n",
    "#    sentiment = analyze_sentiment(text)\n",
    "#    print(text)\n",
    "#    producer.send(produce_topic, sentiment.encode('utf-8'))\n",
    "    \n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    print(message)\n",
    "    # Get the text message from the Kafka message\n",
    "    text = message.value.decode('utf-8')\n",
    "    print(text)\n",
    "    # Tokenize the text message\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Use the BERT model to predict the sentiment\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "    sentiment = int(predictions.argmax(axis=1)[0]) - 1  # Convert 0-4 to -1-3\n",
    "    data = {}\n",
    "    data['sentiment'] = sentiment\n",
    "    data['text-comment'] = text\n",
    "    response = f\"{'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'}\"\n",
    "    data['response'] = response    \n",
    "    json_data = json.dumps(data)\n",
    "    json_string = json.dumps({'sentiment': sentiment,'text': text,'response': response})\n",
    "    print(json_string)\n",
    "    # Produce a response message with the sentiment\n",
    "    #response_message = f\"{text} ({'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'})\"\n",
    "    #producer.send(produce_topic, response_message.encode('utf-8'))\n",
    "    producer.send(produce_topic, json_string.encode('utf-8'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8ba1-7f24-4c39-b571-1d98697b2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On one screen try this in a terminal window to generate messages. Ensure that kcat is installed to test this manually.\n",
    "kcat -t consume-topic  -b \"$KAFKA_HOST\" \\\n",
    " -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \\\n",
    " -X sasl.username=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_ID\" \\\n",
    " -X sasl.password=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET\" -P\n",
    "Testing doesnt look good\n",
    "Is this really worth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21036c-0915-4878-aa27-f9d0a0501ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On another screen try this to get the output from another topic\n",
    " kcat -t produce-topic  -b \"$KAFKA_HOST\" \\\n",
    " -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \\\n",
    " -X sasl.username=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_ID\" \\\n",
    " -X sasl.password=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET\" -C\n",
    "Testing doesnt look good (negative)\n",
    "Is this really worth! (positive)\n",
    "% Reached end of topic produce-topic [0] at offset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26397e76-fcc6-46b0-aaa8-2309e47fac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = ['globex-ret-cgbv--fs---qsv-ajjig.bf2.kafka.rhcloud.com:443']\n",
    "topic = 'consume-topic'\n",
    "produce_topic = 'produce-topic'\n",
    "username = '5c8037b6-8d56-4160-8ea5-e6921d1da5fb'\n",
    "password = 'affyRJrfk2eYJBcQtQDstnVUGcLXA78U'\n",
    "sasl_mechanism = 'PLAIN'\n",
    "security_protocol = 'SASL_SSL'\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    "    auto_offset_reset='latest',\n",
    "    enable_auto_commit=True,\n",
    ")\n",
    "\n",
    "# Set up a Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism\n",
    ")\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Continuously listen for incoming messages and analyze their sentiment\n",
    "#for message in consumer:\n",
    "#    text = message.value.decode('utf-8')\n",
    "#    sentiment = analyze_sentiment(text)\n",
    "#    print(text)\n",
    "#    producer.send(produce_topic, sentiment.encode('utf-8'))\n",
    "    \n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    # Get the text message from the Kafka message\n",
    "    print(message)\n",
    "    print(message.timestamp/1000.0)\n",
    "    timestamp = datetime.fromtimestamp(message.timestamp/1000.0)\n",
    "    timestamp = timestamp.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    print(timestamp)\n",
    "    text = message.value.decode('utf-8')\n",
    "    # May need to use this later - customer_id, product_id, review_text = text.split(\",\")\n",
    "    print(text)\n",
    "    # Tokenize the text message\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Use the BERT model to predict the sentiment\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "    sentiment = int(predictions.argmax(axis=1)[0]) - 1  # Convert 0-4 to -1-3\n",
    "    customer_id = 1023\n",
    "    product_id = 1\n",
    "    data = {}\n",
    "    data['sentiment'] = sentiment\n",
    "    data['text-comment'] = text\n",
    "    response = f\"{'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'}\"\n",
    "    data['response'] = response    \n",
    "    json_data = json.dumps(data)\n",
    "    json_string = json.dumps({'timestamp': timestamp, 'customer_id': customer_id,'product_id': product_id,'sentiment': sentiment,'text': text,'response': response})\n",
    "    print(json_string)\n",
    "   \n",
    "    #sentiment_output = f\"{customer_id},{product_id},{sentiment}\" \n",
    "    # Produce a response message with the sentiment\n",
    "    #response_message = f\"{timestamp} {customer_id},{product_id}, {text} ({'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'})\"\n",
    "    #producer.send(produce_topic, response_message.encode('utf-8'))\n",
    "    \n",
    "    producer.send(produce_topic, json_string.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92594fd-6c1c-49c4-8011-73ebf45b46a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
