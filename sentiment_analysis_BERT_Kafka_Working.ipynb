{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd2f838-68a8-4dc7-966e-40a087342574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in /opt/app-root/lib/python3.8/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b590212-9db2-4673-bc22-740771c25266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/app-root/lib/python3.8/site-packages (4.26.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/app-root/lib/python3.8/site-packages (from transformers) (0.13.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/app-root/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.8/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.8/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231e31ed-c843-4ac2-95cc-070216e18f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.consumer import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d156d7-c6ae-40fb-88a3-0a1284d3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.producer import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1d56fc-d215-4574-9a9c-6b8d3b0f4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from transformers import pipeline\n",
    "import ssl\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1cfc6-f1a2-48e6-b13f-11923691b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def analyze_sentiment(text):\n",
    "#    classifier = pipeline(\"sentiment-analysis\")\n",
    "#    result = classifier(text)[0]\n",
    "#    return result[\"label\"]\n",
    "\n",
    "bootstrap_servers = ['xxxxxxxxxx.kafka.rhcloud.com:443']\n",
    "topic = 'consume-topic'\n",
    "produce_topic = 'produce-topic'\n",
    "username = 'xxxxxxxxxx'\n",
    "password = 'xxxxxxxxxx'\n",
    "sasl_mechanism = 'PLAIN'\n",
    "security_protocol = 'SASL_SSL'\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    "    auto_offset_reset='latest',\n",
    "    enable_auto_commit=True\n",
    ")\n",
    "\n",
    "# Set up a Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism\n",
    ")\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Continuously listen for incoming messages and analyze their sentiment\n",
    "#for message in consumer:\n",
    "#    text = message.value.decode('utf-8')\n",
    "#    sentiment = analyze_sentiment(text)\n",
    "#    print(text)\n",
    "#    producer.send(produce_topic, sentiment.encode('utf-8'))\n",
    "    \n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    # Get the text message from the Kafka message\n",
    "    text = message.value.decode('utf-8')\n",
    "    print(text)\n",
    "    # Tokenize the text message\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Use the BERT model to predict the sentiment\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "    sentiment = int(predictions.argmax(axis=1)[0]) - 1  # Convert 0-4 to -1-3\n",
    "\n",
    "    # Produce a response message with the sentiment\n",
    "    response_message = f\"{text} ({'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'})\"\n",
    "    producer.send(produce_topic, response_message.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8ba1-7f24-4c39-b571-1d98697b2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On one screen try this in a terminal window to generate messages. Ensure that kcat is installed to test this manually.\n",
    "kcat -t consume-topic  -b \"$KAFKA_HOST\" \\\n",
    " -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \\\n",
    " -X sasl.username=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_ID\" \\\n",
    " -X sasl.password=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET\" -P\n",
    "Testing doesnt look good\n",
    "Is this really worth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21036c-0915-4878-aa27-f9d0a0501ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On another screen try this to get the output from another topic\n",
    " kcat -t produce-topic  -b \"$KAFKA_HOST\" \\\n",
    " -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN \\\n",
    " -X sasl.username=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_ID\" \\\n",
    " -X sasl.password=\"$RHOAS_SERVICE_ACCOUNT_CLIENT_SECRET\" -C\n",
    "Testing doesnt look good (negative)\n",
    "Is this really worth! (positive)\n",
    "% Reached end of topic produce-topic [0] at offset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26397e76-fcc6-46b0-aaa8-2309e47fac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 12:17:47.182000\n",
      "This is good as it prints time stamp\n"
     ]
    }
   ],
   "source": [
    "bootstrap_servers = ['XXXXXXXXXX.kafka.rhcloud.com:443']\n",
    "topic = 'consume-topic'\n",
    "produce_topic = 'produce-topic'\n",
    "username = 'XXXXXXXXXX'\n",
    "password = 'XXXXXXXXXX'\n",
    "sasl_mechanism = 'PLAIN'\n",
    "security_protocol = 'SASL_SSL'\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism,\n",
    "    auto_offset_reset='latest',\n",
    "    enable_auto_commit=True,\n",
    ")\n",
    "\n",
    "# Set up a Kafka producer\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    sasl_plain_username=username,\n",
    "    sasl_plain_password=password,\n",
    "    security_protocol=security_protocol,\n",
    "    sasl_mechanism=sasl_mechanism\n",
    ")\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Continuously listen for incoming messages and analyze their sentiment\n",
    "#for message in consumer:\n",
    "#    text = message.value.decode('utf-8')\n",
    "#    sentiment = analyze_sentiment(text)\n",
    "#    print(text)\n",
    "#    producer.send(produce_topic, sentiment.encode('utf-8'))\n",
    "    \n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    # Get the text message from the Kafka message\n",
    "    timestamp = datetime.fromtimestamp(message.timestamp/1000.0)\n",
    "    print(timestamp)\n",
    "    text = message.value.decode('utf-8')\n",
    "    print(text)\n",
    "    # Tokenize the text message\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Use the BERT model to predict the sentiment\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "    sentiment = int(predictions.argmax(axis=1)[0]) - 1  # Convert 0-4 to -1-3\n",
    "    customer_id = 1023\n",
    "    product_id = 1\n",
    "    sentiment_output = f\"{customer_id},{product_id},{sentiment}\" \n",
    "    # Produce a response message with the sentiment\n",
    "    response_message = f\"{timestamp} {customer_id},{product_id}, {text} ({'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'})\"\n",
    "    producer.send(produce_topic, response_message.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92594fd-6c1c-49c4-8011-73ebf45b46a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
